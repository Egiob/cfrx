{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Monte Carlo Counterfactual Regret Minimization (MCCFR)\n",
    "\n",
    "In this example we showcase how to use `cfrx` to run the MCCFR (outcome-sampling variation) on simple games Kuhn Poker, Leduc Poker.\n",
    "\n",
    "We'll see how to:\n",
    " - Initialize an environment from `cfrx`\n",
    " - Initialize a random policy and sample a rollout\n",
    " - Write a small training loop to run the MCCFR algorithm\n",
    " - Measure the evolution of our strategy exploitability throughout the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "jax.config.update(\"jax_platform_name\", \"cpu\")\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from cfrx.algorithms.mccfr.outcome_sampling import MCCFRState, do_iteration, unroll\n",
    "from cfrx.metrics import exploitability\n",
    "from cfrx.policy import TabularPolicy\n",
    "from cfrx.utils import regret_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def plot_partial(plot_fn, *plot_args):\n",
    "    clear_output(wait=True)\n",
    "    fig = plot_fn(*plot_args)\n",
    "    plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = jax.devices(\"cpu\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "ENV_NAME = \"Kuhn Poker\"\n",
    "NUM_ITERATIONS = 100000\n",
    "EXPLORATION_FACTOR = 0.6\n",
    "SEED = 0\n",
    "METRICS_PERIOD = 10000\n",
    "\n",
    "random_key = jax.random.PRNGKey(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENV_NAME == \"Kuhn Poker\":\n",
    "    from cfrx.envs.kuhn_poker.env import KuhnPoker\n",
    "\n",
    "    env_cls = KuhnPoker\n",
    "\n",
    "\n",
    "elif ENV_NAME == \"Leduc Poker\":\n",
    "    from cfrx.envs.leduc_poker.env import LeducPoker\n",
    "\n",
    "    env_cls = LeducPoker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## The environment\n",
    "\n",
    "[Kuhn Poker](https://en.wikipedia.org/wiki/Kuhn_poker) is a simplified version of the Poker game. In cfrx, we use the environment from [pgx](https://github.com/sotetsuk/pgx), and add a wrapper to explicitly handle random nodes and information states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = env_cls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of info_sets, number of possible actions\n",
    "n_states = env.n_info_states\n",
    "n_actions = env.n_actions\n",
    "\n",
    "n_states, n_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = env.init(random_key)\n",
    "s0  # Cards haven't been dealed yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give a J to player 1 and a K to player 2\n",
    "s1 = env.step(s0, action=jnp.array(0))\n",
    "s2 = env.step(s1, action=jnp.array(2))\n",
    "jax.tree_map(lambda *z: jnp.stack(z), s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Random policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a training state\n",
    "training_state = MCCFRState.init(n_states, n_actions)\n",
    "jax.tree_map(np.shape, training_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Policy object and print the probability distribution for our current strategy and state\n",
    "policy = TabularPolicy(\n",
    "    n_actions=n_actions,\n",
    "    exploration_factor=EXPLORATION_FACTOR,\n",
    "    info_state_idx_fn=env.info_state_idx,\n",
    ")\n",
    "\n",
    "policy.prob_distribution(\n",
    "    params=training_state.probs,\n",
    "    info_state=s2.info_state,\n",
    "    action_mask=s2.legal_action_mask,\n",
    "    use_behavior_policy=jnp.bool_(False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do an unroll with our uniformly-random Policy\n",
    "random_key, subkey = jax.random.split(random_key)\n",
    "episode, states = unroll(\n",
    "    init_state=s2,\n",
    "    training_state=training_state,\n",
    "    random_key=subkey,\n",
    "    update_player=0,\n",
    "    env=env,\n",
    "    policy=policy,\n",
    "    n_max_steps=env.max_episode_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Print out the action sequence \"b\" means \"bet\" and \"p\" pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.tree_map(lambda x: x[~states.terminated], states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\".join(\n",
    "    [env_cls.action_to_string(x) for x in episode.action[episode.mask.astype(bool)]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## MCCFR implementation\n",
    "We use the `cfrx` components to implement the MCCFR algorithm.\n",
    "\n",
    "The algorithm consists in alternating iterations for the two players, and logging the exploitability from time to time.\n",
    "\n",
    "Note: We make sure to Jit both the iteration and exploitability function, to make the most of Jax capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function samples a trajectory, compute counterfactual regrets and update the policy accordingly\n",
    "do_iteration_fn = jax.jit(\n",
    "    lambda training_state, random_key, update_player: do_iteration(\n",
    "        training_state=training_state,\n",
    "        random_key=random_key,\n",
    "        env=env,\n",
    "        policy=policy,\n",
    "        update_player=update_player,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function measures the exploitability of a strategy\n",
    "exploitability_fn = jax.jit(\n",
    "    lambda policy_params: exploitability(\n",
    "        policy_params=policy_params,\n",
    "        env=env,\n",
    "        n_players=env.n_players,\n",
    "        n_max_nodes=env.max_nodes,\n",
    "        policy=policy,\n",
    "    ),\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One iteration consists in updating the policy for both players\n",
    "n_loops = 2 * NUM_ITERATIONS\n",
    "\n",
    "exploitabilities = []\n",
    "iterations = []\n",
    "\n",
    "for k in range(n_loops):\n",
    "    random_key, subkey = jax.random.split(random_key)\n",
    "\n",
    "    # Update players alternatively\n",
    "    update_player = k % 2\n",
    "    training_state = do_iteration_fn(\n",
    "        training_state=training_state,\n",
    "        random_key=subkey,\n",
    "        update_player=update_player,\n",
    "    )\n",
    "\n",
    "    # Logging\n",
    "    if k == 0 or (k + 1) % (METRICS_PERIOD * 2) == 0:\n",
    "        current_policy = training_state.avg_probs\n",
    "        current_policy /= training_state.avg_probs.sum(axis=-1, keepdims=True)\n",
    "\n",
    "        exp = exploitability_fn(policy_params=current_policy)\n",
    "\n",
    "        exploitabilities.append(exp)\n",
    "        iterations.append(k // 2)\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.title(f\"MCCFR outcome sampling on {ENV_NAME}\")\n",
    "        plt.ylabel(\"Exploitability\")\n",
    "        plt.yscale(\"log\")\n",
    "        plt.xlim(0, NUM_ITERATIONS)\n",
    "\n",
    "        plot_partial(plt.plot, iterations, exploitabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "All this logic is also implemented inside a trainer, which is further optimized to reduce the runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cfrx.trainers.mccfr import MCCFRTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MCCFRTrainer(env=env, policy=policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_state = trainer.train(\n",
    "    random_key=random_key, n_iterations=NUM_ITERATIONS, metrics_period=METRICS_PERIOD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
